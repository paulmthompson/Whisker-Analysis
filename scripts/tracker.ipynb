{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('C:/Users/wanglab/Documents/Whisker-Analysis/out/build/MSVC/Release')\n",
    "#sys.path.append('C:/Users/wanglab/Documents/Whisker-Analysis/out/build/Clang/Release')\n",
    "#sys.path.append('../out/build/MSVC/Release')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928040247b599c77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-26T17:48:43.873110Z",
     "start_time": "2024-06-26T17:48:42.864127Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import whiskertracker\n",
    "\n",
    "# Create an instance of WhiskerTracker\n",
    "wt = whiskertracker.WhiskerTracker()\n",
    "\n",
    "wt.setWhiskerPad(582, 267)\n",
    "\n",
    "img = cv2.imread('C:/Users/wanglab/Desktop/img0011018.png')\n",
    "\n",
    "if len(img.shape) > 2:\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Flatten the image and convert it to a list of uint8_t\n",
    "image_data = img.flatten().tolist()\n",
    "\n",
    "wt.trace(image_data,480,640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700a2449",
   "metadata": {},
   "outputs": [],
   "source": [
    "dilation_size = 13\n",
    "data_path = \"C:/Users/wanglab/Data/Piezo/NTNG-1-Piezo/053124/4588/1/\"\n",
    "mask_path = data_path + \"mask.png\"\n",
    "video_path = data_path + \"output.mp4\"\n",
    "num_whiskers = 5\n",
    "pad_pos = [566, 275]\n",
    "\n",
    "wt.setWhiskerPad(pad_pos[0], pad_pos[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5536f50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "face_mask = cv2.imread(mask_path)\n",
    "\n",
    "gray_mask = cv2.cvtColor(face_mask, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Step 3: Apply threshold\n",
    "_, thresh = cv2.threshold(gray_mask, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Grow mask to appropriate size\n",
    "element = np.ones((dilation_size, dilation_size), np.uint8)\n",
    "cv2.bitwise_not(thresh, thresh)\n",
    "cv2.dilate(thresh, element, thresh, iterations=1)\n",
    "cv2.bitwise_not(thresh, thresh)\n",
    "\n",
    "# Step 4: Find contours\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Create an empty image for drawing contours\n",
    "contour_img = 255 * np.ones_like(face_mask)\n",
    "\n",
    "# Step 5: Draw contours\n",
    "cv2.drawContours(contour_img, contours, -1, (0, 0, 0), 3)  # Adjust thickness here\n",
    "\n",
    "gray_mask = cv2.cvtColor(contour_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "threshold = 50\n",
    "\n",
    "black_pixels = [(x, y) for y in range(gray_mask.shape[0]) for x in range(gray_mask.shape[1]) if gray_mask[y, x] < threshold]\n",
    "\n",
    "wt.setFaceMask(black_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086ec70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clang fast\n",
    "%timeit wt.trace(image_data,480,640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc9dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = img.flatten().tolist()\n",
    "wt.trace(image_data,480,640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae5342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSVC fast\n",
    "%timeit wt.trace(image_data,480,640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102a7442",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(w0)):\n",
    "    ww = np.reshape(w0[i],(-1,2))\n",
    "    plt.plot(ww[:,0],ww[:,1])\n",
    "plt.xlim(0,640)\n",
    "plt.ylim(0,480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7d3f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vidcap = cv2.VideoCapture(video_path)\n",
    "\n",
    "num_frames = get_total_frames(vidcap)\n",
    "\n",
    "iterable = create_progress_bar(num_frames)\n",
    "\n",
    "whiskers_per_frame = []\n",
    "frames = []\n",
    "\n",
    "output_frames = []\n",
    "\n",
    "for i, frame in iterable:\n",
    "    success, img = vidcap.read()\n",
    "\n",
    "    if success:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        image_data = img.flatten().tolist()\n",
    "\n",
    "        wt.trace(image_data,480,640)\n",
    "\n",
    "        w0 = wt.getWhiskers()\n",
    "\n",
    "        frames.append(i)\n",
    "\n",
    "        whiskers_per_frame.append([])\n",
    "        for j in range(0,len(w0)):\n",
    "            ww = np.reshape(w0[j],(-1,2))\n",
    "            whiskers_per_frame[-1].append(ww)\n",
    "    else:\n",
    "        print(f\"Failed to read frame {i}\")\n",
    "\n",
    "\n",
    "vidcap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2089da",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_to_plot = 8\n",
    "for i in range(0,len(whiskers_per_frame[frame_to_plot])):\n",
    "    ww = whiskers_per_frame[frame_to_plot][i]\n",
    "    plt.plot(ww[:,0],ww[:,1])\n",
    "\n",
    "plt.xlim(0,640)\n",
    "plt.ylim(0,480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36935a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w_id in range(0,num_whiskers):\n",
    "    with h5py.File(data_path + f\"whisker_{w_id}.h5\", \"w\") as f:\n",
    "        frames = np.array(frames, dtype=np.int64)\n",
    "        f.create_dataset(\"frames\", data=frames, dtype=np.int64)\n",
    "\n",
    "        dt_float = h5py.vlen_dtype(np.dtype(\"float32\"))\n",
    "\n",
    "        x = np.empty(len(frames),dtype=object)\n",
    "        y = np.empty(len(frames),dtype=object)\n",
    "\n",
    "        for i, whiskers in enumerate(whiskers_per_frame):\n",
    "\n",
    "            if len(whiskers) <= w_id:\n",
    "                x[i] = np.array([],dtype=np.float32)\n",
    "                y[i] = np.array([],dtype=np.float32)\n",
    "                continue\n",
    "\n",
    "            w = whiskers[w_id]\n",
    "\n",
    "            x[i] = w[:,1]\n",
    "            y[i] = w[:,0]\n",
    "\n",
    "        f.create_dataset(\"x\", data=x, dtype=dt_float)\n",
    "        f.create_dataset(\"y\", data=y, dtype=dt_float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a47492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "def create_progress_bar(num_frames, label=\"Train\"):\n",
    "    \"\"\"\n",
    "    Creates a progress bar that increments with each frame processed\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_frames: int\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    iterable = enumerate(range(0, num_frames))\n",
    "    progress = tqdm(\n",
    "        iterable, desc=label, total=num_frames, ascii=True, leave=True, position=0\n",
    "    )\n",
    "    iterable = progress\n",
    "    return iterable\n",
    "\n",
    "\n",
    "def get_total_frames(vidcap):\n",
    "    num_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Total number of frames in video {num_frames}\")\n",
    "    return num_frames"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
